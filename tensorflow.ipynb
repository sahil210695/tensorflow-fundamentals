{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow (v1.10)\n",
    "TensorFlow™ is an open source software library for numerical computation using data flow graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Basic](#1.-Basic)\n",
    "2. [Normal Loading](#2.-Normal-Loading)\n",
    "3. [Lazy Loading](#3.-Lazy-Loading)\n",
    "4. [Complete Program](#4.-Complete-Program)\n",
    "5. [Linear Regression in Tensorflow](#5.-Linear-Regression-in-Tensorflow)\n",
    "6. [Logistic Regression in Tensorflow](#6.-Logistic-Regression-in-Tensorflow)\n",
    "7. [Logistic Regression in Tensorflow (Improved Accuracy)](#7.-Logistic-Regression-in-Tensorflow-%28Improved-Accuracy%29)\n",
    "8. [Word2Vec](#8.-Word2Vec)\n",
    "9. [Word2Vec Visualize](#9.-Word2Vec-Visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of constant is:  6\n",
      "Placeholder c is:  1\n"
     ]
    }
   ],
   "source": [
    "# reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# constant\n",
    "a = tf.constant(3, name='a')\n",
    "b = tf.constant(3, name='b')\n",
    "c = tf.add(a, b, name='sum')\n",
    "\n",
    "# variables\n",
    "s = tf.Variable(2, name=\"scalar\") \n",
    "m = tf.Variable([[0, 1], [2, 3]], name=\"matrix\") \n",
    "W = tf.Variable(tf.zeros([784,10]), name=\"big_matrix\")\n",
    "\n",
    "# placeholders\n",
    "q = tf.placeholder(tf.int32, shape=None, name=\"q\")\n",
    "\n",
    "# write summary for tensorboard\n",
    "writer = tf.summary.FileWriter('summary/basic', tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('Sum of constant is: ', sess.run(c))\n",
    "    print('Placeholder c is: ', sess.run(q, feed_dict = {q : 1}))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Normal Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "z = tf.add(x, y)        # create the node before executing the graph\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # summary for tensorboard\n",
    "    writer = tf.summary.FileWriter('summary/normal_loading', sess.graph)\n",
    "    \n",
    "    for _ in range(5):\n",
    "        print(sess.run(z))\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# uncomment to see graph def (here Add op will be added 1 time only in graph)\n",
    "# print tf.get_default_graph().as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Lazy Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for _ in range(5):\n",
    "        print(sess.run(tf.add(x, y))) # someone decides to be clever to save one line of code\n",
    "        \n",
    "    # summary for tensorboard (I've added this after running the seesion to see the effect of lazy loading)\n",
    "    writer = tf.summary.FileWriter('summary/lazy_loading', sess.graph)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# uncomment to see the graph def (here Add op will be added 5 times in graph)\n",
    "# print tf.get_default_graph().as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Complete Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value at last step: 0.14925916492938995\n",
      "[[-0.62195325]\n",
      " [-1.301379  ]\n",
      " [-1.9808047 ]\n",
      " [-2.6602304 ]]\n"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
    "\n",
    "#train label\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n",
    "\n",
    "y_pred = tf.layers.dense(x, units = 1)\n",
    "\n",
    "#loss metric\n",
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "#loss optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # training 100 steps\n",
    "    for i in range(100):\n",
    "        _, loss_value = sess.run([train, loss])\n",
    "    \n",
    "    # loss value\n",
    "    print('loss value at last step: {}'.format(loss_value))\n",
    "\n",
    "    # predicted labels\n",
    "    print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Linear Regression in Tensorflow\n",
    "- X: birth rate\n",
    "- Y: life expectancy\n",
    "- Find a linear relationship between X and Y, to predict Y from X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/linear_regression.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from data/birth_life_2010.txt (in my case)\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def read_birth_life_data(filename):\n",
    "    \"\"\"\n",
    "    Read in birth_life_2010.txt and return:\n",
    "    data in the form of NumPy array\n",
    "    n_samples: number of samples\n",
    "    \"\"\"\n",
    "    text = open(filename, 'r').readlines()[1:]\n",
    "    data = [line[:-1].split('\\t') for line in text]\n",
    "    births = [float(line[1]) for line in data]\n",
    "    lifes = [float(line[2]) for line in data]\n",
    "    data = list(zip(births, lifes))\n",
    "    n_samples = len(data)\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    \n",
    "    return data, n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Step 1: read in data from the .txt file\n",
    "data, n_samples = read_birth_life_data('data/birth_life_2010.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\n",
    "# Remember both X and Y are scalars with type float\n",
    "X = tf.placeholder(dtype=tf.float32, shape=None, name='X')\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=None, name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: create weight and bias, initialized to 0.0\n",
    "# Make sure to use tf.get_variable\n",
    "w = tf.get_variable('weight', dtype=None, shape=None, initializer=0.0)\n",
    "b = tf.get_variable('bias', dtype=None, shape=None, initializer=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: build model to predict Y\n",
    "# e.g. how would you derive at Y_predicted given X, w, and b\n",
    "# Y_predicted = None\n",
    "Y_predicted = w * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: use the square error as the loss function\n",
    "loss = tf.square(Y - Y_predicted, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: using gradient descent with learning rate of 0.001 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1661.863764550287\n",
      "Epoch 20: 119.20935661137888\n",
      "Epoch 40: 37.305592010505066\n",
      "Epoch 60: 30.524589418089263\n",
      "Epoch 80: 30.04458791257593\n",
      "Epoch 100: 30.036051805281865\n",
      "Took: 10.035122871398926 seconds\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Create a filewriter to write the model's graph to TensorBoard\n",
    "    writer = tf.summary.FileWriter('summary/linear_regresssion', sess.graph)\n",
    "    \n",
    "    for i in range(101):\n",
    "        total_loss = 0\n",
    "        for x, y in data:\n",
    "            # Execute train_op and get the value of loss.\n",
    "            # Don't forget to feed in data for placeholders\n",
    "            _, loss_value = sess.run([optimizer, loss], feed_dict={X:x, Y:y})\n",
    "            total_loss += loss_value\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            # print loss at each 20th Epoch\n",
    "            print('Epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    "    \n",
    "    # close the writer when you're done using it\n",
    "    writer.close()\n",
    "    \n",
    "    # Step 9: output the values of w and b\n",
    "    w_out, b_out = sess.run([w, b])\n",
    "\n",
    "print('Took: {0} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the following lines to see the plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n",
    "plt.plot(data[:,0], data[:,0] * w_out + b_out, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Logistic Regression in Tensorflow\n",
    "- MNIST Database (Each image is a 28x28 array, flattened out to be a 1-d tensor of size 784)\n",
    "- X: image of a handwritten digit\n",
    "- Y: the digit value\n",
    "- Recognize the digit in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logistic_regression.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import struct\n",
    "import urllib\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def safe_mkdir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def download_one_file(download_url, \n",
    "                    local_dest, \n",
    "                    expected_byte=None, \n",
    "                    unzip_and_remove=False):\n",
    "    \"\"\" \n",
    "    Download the file from download_url into local_dest\n",
    "    if the file doesn't already exists.\n",
    "    If expected_byte is provided, check if \n",
    "    the downloaded file has the same number of bytes.\n",
    "    If unzip_and_remove is True, unzip the file and remove the zip file\n",
    "    \"\"\"\n",
    "    if os.path.exists(local_dest) or os.path.exists(local_dest[:-3]):\n",
    "        print('%s already exists' %local_dest)\n",
    "    else:\n",
    "        print('Downloading %s' %download_url)\n",
    "        local_file, _ = urllib.urlretrieve(download_url, local_dest)\n",
    "        file_stat = os.stat(local_dest)\n",
    "        if expected_byte:\n",
    "            if file_stat.st_size == expected_byte:\n",
    "                print('Successfully downloaded %s' %local_dest)\n",
    "                if unzip_and_remove:\n",
    "                    with gzip.open(local_dest, 'rb') as f_in, open(local_dest[:-3],'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "                    os.remove(local_dest)\n",
    "            else:\n",
    "                print('The downloaded file has unexpected number of bytes')\n",
    "\n",
    "\n",
    "def download_mnist(path):\n",
    "    \"\"\" \n",
    "    Download and unzip the dataset mnist if it's not already downloaded \n",
    "    Download from http://yann.lecun.com/exdb/mnist\n",
    "    \"\"\"\n",
    "    safe_mkdir(path)\n",
    "    url = 'http://yann.lecun.com/exdb/mnist'\n",
    "    filenames = ['train-images-idx3-ubyte.gz',\n",
    "                'train-labels-idx1-ubyte.gz',\n",
    "                't10k-images-idx3-ubyte.gz',\n",
    "                't10k-labels-idx1-ubyte.gz']\n",
    "    expected_bytes = [9912422, 28881, 1648877, 4542]\n",
    "\n",
    "    for filename, byte in zip(filenames, expected_bytes):\n",
    "        download_url = os.path.join(url, filename)\n",
    "        local_dest = os.path.join(path, filename)\n",
    "        download_one_file(download_url, local_dest, byte, True)\n",
    "        \n",
    "\n",
    "def parse_data(path, dataset, flatten):\n",
    "    if dataset != 'train' and dataset != 't10k':\n",
    "        raise NameError('dataset must be train or t10k')\n",
    "\n",
    "    label_file = os.path.join(path, dataset + '-labels-idx1-ubyte')\n",
    "    with open(label_file, 'rb') as file:\n",
    "        _, num = struct.unpack(\">II\", file.read(8))\n",
    "        labels = np.fromfile(file, dtype=np.int8) #int8\n",
    "        new_labels = np.zeros((num, 10))\n",
    "        new_labels[np.arange(num), labels] = 1\n",
    "    \n",
    "    img_file = os.path.join(path, dataset + '-images-idx3-ubyte')\n",
    "    with open(img_file, 'rb') as file:\n",
    "        _, num, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        imgs = np.fromfile(file, dtype=np.uint8).reshape(num, rows, cols) #uint8\n",
    "        imgs = imgs.astype(np.float32) / 255.0\n",
    "        if flatten:\n",
    "            imgs = imgs.reshape([num, -1])\n",
    "\n",
    "    return imgs, new_labels\n",
    "\n",
    "\n",
    "def read_mnist(path, flatten=True, num_train=55000):\n",
    "    \"\"\"\n",
    "    Read in the mnist dataset, given that the data is stored in path\n",
    "    Return two tuples of numpy arrays\n",
    "    ((train_imgs, train_labels), (test_imgs, test_labels))\n",
    "    \"\"\"\n",
    "    imgs, labels = parse_data(path, 'train', flatten)\n",
    "    indices = np.random.permutation(labels.shape[0])\n",
    "    train_idx, val_idx = indices[:num_train], indices[num_train:]\n",
    "    train_img, train_labels = imgs[train_idx, :], labels[train_idx, :]\n",
    "    val_img, val_labels = imgs[val_idx, :], labels[val_idx, :]\n",
    "    test = parse_data(path, 't10k', flatten)\n",
    "    \n",
    "    return (train_img, train_labels), (val_img, val_labels), test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "learning_rate = 0.1\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "n_train = 60000\n",
    "n_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mnist\\train-images-idx3-ubyte.gz already exists\n",
      "data/mnist\\train-labels-idx1-ubyte.gz already exists\n",
      "data/mnist\\t10k-images-idx3-ubyte.gz already exists\n",
      "data/mnist\\t10k-labels-idx1-ubyte.gz already exists\n"
     ]
    }
   ],
   "source": [
    "# reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Step 1: Read in data\n",
    "mnist_folder = 'data/mnist'\n",
    "download_mnist(mnist_folder)\n",
    "train, val, test = read_mnist(mnist_folder, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 0.3668709104490835\n",
      "Average loss epoch 10: 0.2649705114579478\n",
      "Average loss epoch 20: 0.25902860464398253\n",
      "Average loss epoch 30: 0.2536010127081427\n",
      "Total time: 69.29058146476746 seconds\n",
      "Accuracy 0.917\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create datasets and iterator\n",
    "# create training Dataset and batch it\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_data = train_data.shuffle(10000) # if you want to shuffle your data\n",
    "train_data = train_data.batch(batch_size)\n",
    "\n",
    "# create testing Dataset and batch it\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_data = test_data.batch(batch_size)\n",
    "\n",
    "# create one iterator and initialize it with different datasets\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types, \n",
    "                                           train_data.output_shapes)\n",
    "img, label = iterator.get_next()\n",
    "\n",
    "train_init = iterator.make_initializer(train_data) # initializer for train_data\n",
    "test_init = iterator.make_initializer(test_data) # initializer for train_data\n",
    "\n",
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "\n",
    "w = tf.get_variable('weight', shape=[784, 10], initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01))\n",
    "b = tf.get_variable('bias', shape=[1, 10], initializer=tf.zeros_initializer())\n",
    "\n",
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "logits = tf.matmul(img, w) + b\n",
    "\n",
    "# Step 5: define loss function\n",
    "# use cross entropy of softmax of logits as the loss function\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "# Step 6: define optimizer\n",
    "# using Adamn Optimizer with pre-defined learning rate to minimize loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "# Step 7: calculate accuracy with test set\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "writer = tf.summary.FileWriter('summary/logreg', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # train the model n_epochs times\n",
    "    for i in range(n_epochs + 1):\n",
    "        sess.run(train_init) # drawing samples from train_data\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss])\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            # print loss after every 10th epoch\n",
    "            print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "            \n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "    # test the model\n",
    "    sess.run(test_init) # drawing samples from test_data\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/n_test))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Logistic Regression in Tensorflow (Improved Accuracy)\n",
    "- MNIST Database (Each image is a 28x28 array, flattened out to be a 1-d tensor of size 784)\n",
    "- X: image of a handwritten digit\n",
    "- Y: the digit value\n",
    "- Recognize the digit in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/logistic_regression_mnist.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "learning_rate = 0.1\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "n_train = 60000\n",
    "n_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mnist\\train-images-idx3-ubyte.gz already exists\n",
      "data/mnist\\train-labels-idx1-ubyte.gz already exists\n",
      "data/mnist\\t10k-images-idx3-ubyte.gz already exists\n",
      "data/mnist\\t10k-labels-idx1-ubyte.gz already exists\n"
     ]
    }
   ],
   "source": [
    "# reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Step 1: Read in data\n",
    "mnist_folder = 'data/mnist'\n",
    "download_mnist(mnist_folder)\n",
    "train, val, test = read_mnist(mnist_folder, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 0.23915461766165355\n",
      "Average loss epoch 10: 0.05518065815501126\n",
      "Average loss epoch 20: 0.038582445789468525\n",
      "Average loss epoch 30: 0.037943312981743214\n",
      "Total time: 140.14170002937317 seconds\n",
      "Accuracy 0.9754\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create datasets and iterator\n",
    "# create training Dataset and batch it\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_data = train_data.shuffle(10000) # if you want to shuffle your data\n",
    "train_data = train_data.batch(batch_size)\n",
    "\n",
    "# create testing Dataset and batch it\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_data = test_data.batch(batch_size)\n",
    "\n",
    "# create one iterator and initialize it with different datasets\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types, \n",
    "                                           train_data.output_shapes)\n",
    "img, label = iterator.get_next()\n",
    "\n",
    "train_init = iterator.make_initializer(train_data) # initializer for train_data\n",
    "test_init = iterator.make_initializer(test_data) # initializer for train_data\n",
    "\n",
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "\n",
    "w_1 = tf.get_variable('weight_1', shape=[784, 200], initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01))\n",
    "b_1 = tf.get_variable('bias_1', shape=[1, 200], initializer=tf.zeros_initializer())\n",
    "\n",
    "w_2 = tf.get_variable('weight_2', shape=[200, 10], initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01))\n",
    "b_2 = tf.get_variable('bias_2', shape=[1, 10], initializer=tf.zeros_initializer())\n",
    "\n",
    "# w_3 = tf.get_variable('weight_3', shape=[100, 60], initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01))\n",
    "# b_3 = tf.get_variable('bias_3', shape=[1, 60], initializer=tf.zeros_initializer())\n",
    "\n",
    "# Step 4: build model\n",
    "# the model that returns the logits.\n",
    "# this logits will be later passed through softmax layer\n",
    "# to get the probability distribution of possible label of the image\n",
    "# DO NOT DO SOFTMAX HERE\n",
    "\n",
    "hidden_1 = tf.nn.relu(tf.matmul(img, w_1) + b_1)\n",
    "# hidden_2 = tf.nn.relu(tf.matmul(hidden_1, w_2) + b_2)\n",
    "logits = tf.matmul(hidden_1, w_2) + b_2\n",
    "\n",
    "# Step 5: define loss function\n",
    "# use cross entropy of softmax of logits as the loss function\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=logits)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "# Step 6: define optimizer\n",
    "# using Adamn Optimizer with pre-defined learning rate to minimize loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "# Step 7: calculate accuracy with test set\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "# writer = tf.summary.FileWriter('summary/logreg_acc', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # train the model n_epochs times\n",
    "    for i in range(n_epochs + 1):\n",
    "        sess.run(train_init) # drawing samples from train_data\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss])\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            # print loss after every 10th epoch\n",
    "            print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "            \n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "    # test the model\n",
    "    sess.run(test_init)\t\t\t# drawing samples from test_data\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/n_test))\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Word2Vec\n",
    "- Skip-gram model with NCE loss\n",
    "- TensorFlow doesn’t know what nodes should be grouped together, unless you tell it to (Group nodes together with **tf.name_scope(name)**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/word2vec.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for Word2Vec\n",
    "\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def read_data(file_path):\n",
    "    \"\"\" Read data into a list of tokens \n",
    "    There should be 17,005,207 tokens\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(file_path) as f:\n",
    "        words = tf.compat.as_str(f.read(f.namelist()[0])).split() \n",
    "    return words\n",
    "\n",
    "def build_vocab(words, vocab_size, visual_fld):\n",
    "    \"\"\" Build vocabulary of VOCAB_SIZE most frequent words and write it to\n",
    "    visualization/vocab.tsv\n",
    "    \"\"\"\n",
    "    safe_mkdir(visual_fld)\n",
    "    file = open(os.path.join(visual_fld, 'vocab.tsv'), 'w')\n",
    "    \n",
    "    dictionary = dict()\n",
    "    count = [('UNK', -1)]\n",
    "    index = 0\n",
    "    count.extend(Counter(words).most_common(vocab_size - 1))\n",
    "    \n",
    "    for word, _ in count:\n",
    "        dictionary[word] = index\n",
    "        index += 1\n",
    "        file.write(word + '\\n')\n",
    "    \n",
    "    index_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    file.close()\n",
    "    return dictionary, index_dictionary\n",
    "\n",
    "def convert_words_to_index(words, dictionary):\n",
    "    \"\"\" Replace each word in the dataset with its index in the dictionary \"\"\"\n",
    "    return [dictionary[word] if word in dictionary else 0 for word in words]\n",
    "\n",
    "def generate_sample(index_words, context_window_size):\n",
    "    \"\"\" Form training pairs according to the skip-gram model. \"\"\"\n",
    "    for index, center in enumerate(index_words):\n",
    "        context = random.randint(1, context_window_size)\n",
    "        # get a random target before the center word\n",
    "        for target in index_words[max(0, index - context): index]:\n",
    "            yield center, target\n",
    "        # get a random target after the center wrod\n",
    "        for target in index_words[index + 1: index + context + 1]:\n",
    "            yield center, target\n",
    "\n",
    "def most_common_words(visual_fld, num_visualize):\n",
    "    \"\"\" create a list of num_visualize most frequent words to visualize on TensorBoard.\n",
    "    saved to visualization/vocab_[num_visualize].tsv\n",
    "    \"\"\"\n",
    "    words = open(os.path.join(visual_fld, 'vocab.tsv'), 'r').readlines()[:num_visualize]\n",
    "    words = [word for word in words]\n",
    "    file = open(os.path.join(visual_fld, 'vocab_' + str(num_visualize) + '.tsv'), 'w')\n",
    "    for word in words:\n",
    "        file.write(word)\n",
    "    file.close()\n",
    "\n",
    "def batch_gen(download_url, expected_byte, vocab_size, batch_size, \n",
    "                skip_window, visual_fld):\n",
    "    local_dest = 'data/text8.zip'\n",
    "    download_one_file(download_url, local_dest, expected_byte)\n",
    "    words = read_data(local_dest)\n",
    "    dictionary, _ = build_vocab(words, vocab_size, visual_fld)\n",
    "    index_words = convert_words_to_index(words, dictionary)\n",
    "    del words           # to save memory\n",
    "    single_gen = generate_sample(index_words, skip_window)\n",
    "    \n",
    "    while True:\n",
    "        center_batch = np.zeros(batch_size, dtype=np.int32)\n",
    "        target_batch = np.zeros([batch_size, 1])\n",
    "        for index in range(batch_size):\n",
    "            center_batch[index], target_batch[index] = next(single_gen)\n",
    "        yield center_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "VOCAB_SIZE = 50000\n",
    "BATCH_SIZE = 128\n",
    "EMBED_SIZE = 128            # dimension of the word embedding vectors\n",
    "SKIP_WINDOW = 1             # the context window\n",
    "NUM_SAMPLED = 64            # number of negative examples to sample\n",
    "LEARNING_RATE = 1.0\n",
    "NUM_TRAIN_STEPS = 100000\n",
    "VISUAL_FLD = 'visualization'\n",
    "SKIP_STEP = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for downloading data\n",
    "DOWNLOAD_URL = 'http://mattmahoney.net/dc/text8.zip'\n",
    "EXPECTED_BYTES = 31344016\n",
    "NUM_VISUALIZE = 3000        # number of tokens to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/text8.zip already exists\n",
      "Average loss at step 4999:  65.3\n",
      "Average loss at step 9999:  18.4\n",
      "Average loss at step 14999:   9.6\n",
      "Average loss at step 19999:   6.7\n",
      "Average loss at step 24999:   5.7\n",
      "Average loss at step 29999:   5.2\n",
      "Average loss at step 34999:   5.0\n",
      "Average loss at step 39999:   4.9\n",
      "Average loss at step 44999:   4.8\n",
      "Average loss at step 49999:   4.8\n",
      "Average loss at step 54999:   4.8\n",
      "Average loss at step 59999:   4.7\n",
      "Average loss at step 64999:   4.6\n",
      "Average loss at step 69999:   4.7\n",
      "Average loss at step 74999:   4.6\n",
      "Average loss at step 79999:   4.6\n",
      "Average loss at step 84999:   4.7\n",
      "Average loss at step 89999:   4.7\n",
      "Average loss at step 94999:   4.6\n",
      "Average loss at step 99999:   4.6\n"
     ]
    }
   ],
   "source": [
    "# before starting reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def word2vec(dataset):\n",
    "    \"\"\" Build the graph for word2vec model and train it \"\"\"\n",
    "    # Step 1: get input, output from the dataset\n",
    "    with tf.name_scope('data'):\n",
    "        iterator = dataset.make_initializable_iterator()\n",
    "        center_words, target_words = iterator.get_next()\n",
    "\n",
    "    \"\"\" Step 2 + 3: define weights and embedding lookup.\n",
    "    In word2vec, it's actually the weights that we care about \n",
    "    \"\"\"\n",
    "    with tf.name_scope('embed'):\n",
    "        embed_matrix = tf.get_variable('embed_matrix', \n",
    "                                        shape=[VOCAB_SIZE, EMBED_SIZE],\n",
    "                                        initializer=tf.random_uniform_initializer())\n",
    "        embed = tf.nn.embedding_lookup(embed_matrix, center_words, name='embedding')\n",
    "\n",
    "    # Step 4: construct variables for NCE loss and define loss function\n",
    "    with tf.name_scope('loss'):\n",
    "        nce_weight = tf.get_variable('nce_weight', shape=[VOCAB_SIZE, EMBED_SIZE],\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=1.0 / (EMBED_SIZE ** 0.5)))\n",
    "        nce_bias = tf.get_variable('nce_bias', initializer=tf.zeros([VOCAB_SIZE]))\n",
    "\n",
    "        # define loss function to be NCE loss function\n",
    "        loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n",
    "                                            biases=nce_bias, \n",
    "                                            labels=target_words, \n",
    "                                            inputs=embed, \n",
    "                                            num_sampled=NUM_SAMPLED, \n",
    "                                            num_classes=VOCAB_SIZE), name='loss')\n",
    "\n",
    "    # Step 5: define optimizer\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    safe_mkdir('checkpoints')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator.initializer)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        total_loss = 0.0 # we use this to calculate late average loss in the last SKIP_STEP steps\n",
    "        writer = tf.summary.FileWriter('summary/word2vec_simple', sess.graph)\n",
    "\n",
    "        for index in range(NUM_TRAIN_STEPS):\n",
    "            try:\n",
    "                loss_batch, _ = sess.run([loss, optimizer])\n",
    "                total_loss += loss_batch\n",
    "                if (index + 1) % SKIP_STEP == 0:\n",
    "                    print('Average loss at step {}: {:5.1f}'.format(index, total_loss / SKIP_STEP))\n",
    "                    total_loss = 0.0\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                sess.run(iterator.initializer)\n",
    "        writer.close()\n",
    "\n",
    "def gen():\n",
    "    yield from batch_gen(DOWNLOAD_URL, EXPECTED_BYTES, VOCAB_SIZE, \n",
    "                                        BATCH_SIZE, SKIP_WINDOW, VISUAL_FLD)\n",
    "\n",
    "def main():\n",
    "    dataset = tf.data.Dataset.from_generator(gen, \n",
    "                                (tf.int32, tf.int32), \n",
    "                                (tf.TensorShape([BATCH_SIZE]), tf.TensorShape([BATCH_SIZE, 1])))\n",
    "    word2vec(dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Word2Vec Visualize\n",
    "- Same model hyperparameters as above\n",
    "- t-SNE visualization for Word Vectors\n",
    "- Define a class for your model for reusability of your model\n",
    "- For big models that take a long time to build, save the graph_def in a file and then load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name histogram loss is illegal; using histogram_loss instead.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\skip-gram-99999\n",
      "data/text8.zip already exists\n",
      "Average loss at step 104999:   4.5\n",
      "Average loss at step 109999:   4.5\n",
      "Average loss at step 114999:   4.5\n",
      "Average loss at step 119999:   4.4\n",
      "Average loss at step 124999:   4.5\n",
      "Average loss at step 129999:   4.5\n",
      "Average loss at step 134999:   4.5\n",
      "Average loss at step 139999:   4.4\n",
      "Average loss at step 144999:   4.4\n",
      "Average loss at step 149999:   4.4\n",
      "Average loss at step 154999:   4.5\n",
      "Average loss at step 159999:   4.4\n",
      "Average loss at step 164999:   4.4\n",
      "Average loss at step 169999:   4.4\n",
      "Average loss at step 174999:   4.4\n",
      "Average loss at step 179999:   4.4\n",
      "Average loss at step 184999:   4.4\n",
      "Average loss at step 189999:   4.5\n",
      "Average loss at step 194999:   4.4\n",
      "Average loss at step 199999:   4.4\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\skip-gram-199999\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "# reset the default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "class SkipGramModel:\n",
    "    \"\"\" Build the graph for word2vec model \"\"\"\n",
    "    def __init__(self, dataset, vocab_size, embed_size, batch_size, num_sampled, learning_rate):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_sampled = num_sampled\n",
    "        self.lr = learning_rate\n",
    "        self.global_step = tf.get_variable('global_step', initializer=tf.constant(0), trainable=False)\n",
    "        self.skip_step = SKIP_STEP\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def _import_data(self):\n",
    "        \"\"\" Step 1: import data\n",
    "        \"\"\"\n",
    "        with tf.name_scope('data'):\n",
    "            self.iterator = self.dataset.make_initializable_iterator()\n",
    "            self.center_words, self.target_words = self.iterator.get_next()\n",
    "\n",
    "    def _create_embedding(self):\n",
    "        \"\"\" Step 2 + 3: define weights and embedding lookup.\n",
    "        In word2vec, it's actually the weights that we care about \n",
    "        \"\"\"\n",
    "        with tf.name_scope('embed'):\n",
    "            self.embed_matrix = tf.get_variable('embed_matrix', \n",
    "                                                shape=[self.vocab_size, self.embed_size],\n",
    "                                                initializer=tf.random_uniform_initializer())\n",
    "            self.embed = tf.nn.embedding_lookup(self.embed_matrix, self.center_words, name='embedding')\n",
    "\n",
    "    def _create_loss(self):\n",
    "        \"\"\" Step 4: define the loss function \"\"\"\n",
    "        with tf.name_scope('loss'):\n",
    "            # construct variables for NCE loss\n",
    "            nce_weight = tf.get_variable('nce_weight', \n",
    "                        shape=[self.vocab_size, self.embed_size],\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=1.0 / (self.embed_size ** 0.5)))\n",
    "            nce_bias = tf.get_variable('nce_bias', initializer=tf.zeros([VOCAB_SIZE]))\n",
    "\n",
    "            # define loss function to be NCE loss function\n",
    "            self.loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n",
    "                                                biases=nce_bias, \n",
    "                                                labels=self.target_words, \n",
    "                                                inputs=self.embed, \n",
    "                                                num_sampled=self.num_sampled, \n",
    "                                                num_classes=self.vocab_size), name='loss')\n",
    "    def _create_optimizer(self):\n",
    "        \"\"\" Step 5: define optimizer \"\"\"\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss, \n",
    "                                                              global_step=self.global_step)\n",
    "\n",
    "    def _create_summaries(self):\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.histogram('histogram loss', self.loss)\n",
    "            # because you have several summaries, we should merge them all\n",
    "            # into one op to make it easier to manage\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\" Build the graph for our model \"\"\"\n",
    "        self._import_data()\n",
    "        self._create_embedding()\n",
    "        self._create_loss()\n",
    "        self._create_optimizer()\n",
    "        self._create_summaries()\n",
    "\n",
    "    def train(self, num_train_steps):\n",
    "        saver = tf.train.Saver() # defaults to saving all variables - in this case embed_matrix, nce_weight, nce_bias\n",
    "\n",
    "        initial_step = 0\n",
    "        safe_mkdir('checkpoints')\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.iterator.initializer)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "\n",
    "            # if that checkpoint exists, restore from checkpoint\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "            total_loss = 0.0 # we use this to calculate late average loss in the last SKIP_STEP steps\n",
    "            writer = tf.summary.FileWriter('summary/word2vec/lr' + str(self.lr), sess.graph)\n",
    "            initial_step = self.global_step.eval()\n",
    "\n",
    "            for index in range(initial_step, initial_step + num_train_steps):\n",
    "                try:\n",
    "                    loss_batch, _, summary = sess.run([self.loss, self.optimizer, self.summary_op])\n",
    "                    writer.add_summary(summary, global_step=index)\n",
    "                    total_loss += loss_batch\n",
    "                    if (index + 1) % self.skip_step == 0:\n",
    "                        print('Average loss at step {}: {:5.1f}'.format(index, total_loss / self.skip_step))\n",
    "                        total_loss = 0.0\n",
    "                        saver.save(sess, 'checkpoints/skip-gram', index)\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    sess.run(self.iterator.initializer)\n",
    "            writer.close()\n",
    "\n",
    "    def visualize(self, visual_fld, num_visualize):\n",
    "        \"\"\" run \"'tensorboard --logdir='visualization'\" to see the embeddings \"\"\"\n",
    "        \n",
    "        # create the list of num_variable most common words to visualize\n",
    "        most_common_words(visual_fld, num_visualize)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "\n",
    "            # if that checkpoint exists, restore from checkpoint\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "            final_embed_matrix = sess.run(self.embed_matrix)\n",
    "            \n",
    "            # you have to store embeddings in a new variable\n",
    "            embedding_var = tf.Variable(final_embed_matrix[:num_visualize], name='embedding')\n",
    "            sess.run(embedding_var.initializer)\n",
    "\n",
    "            config = projector.ProjectorConfig()\n",
    "            summary_writer = tf.summary.FileWriter(visual_fld)\n",
    "\n",
    "            # add embedding to the config file\n",
    "            embedding = config.embeddings.add()\n",
    "            embedding.tensor_name = embedding_var.name\n",
    "            \n",
    "            # link this tensor to its metadata file, in this case the first NUM_VISUALIZE words of vocab\n",
    "            embedding.metadata_path = 'vocab_' + str(num_visualize) + '.tsv'\n",
    "\n",
    "            # saves a configuration file that TensorBoard will read during startup.\n",
    "            projector.visualize_embeddings(summary_writer, config)\n",
    "            saver_embed = tf.train.Saver([embedding_var])\n",
    "            saver_embed.save(sess, os.path.join(visual_fld, 'model.ckpt'), 1)\n",
    "\n",
    "def gen():\n",
    "    yield from batch_gen(DOWNLOAD_URL, EXPECTED_BYTES, VOCAB_SIZE, \n",
    "                                        BATCH_SIZE, SKIP_WINDOW, VISUAL_FLD)\n",
    "\n",
    "def main():\n",
    "    dataset = tf.data.Dataset.from_generator(gen, \n",
    "                                (tf.int32, tf.int32), \n",
    "                                (tf.TensorShape([BATCH_SIZE]), tf.TensorShape([BATCH_SIZE, 1])))\n",
    "    model = SkipGramModel(dataset, VOCAB_SIZE, EMBED_SIZE, BATCH_SIZE, NUM_SAMPLED, LEARNING_RATE)\n",
    "    model.build_graph()\n",
    "    model.train(NUM_TRAIN_STEPS)\n",
    "    model.visualize(VISUAL_FLD, NUM_VISUALIZE)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Coming Soon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
